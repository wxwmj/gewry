import asyncio
import aiohttp
import base64
import time
import os
from urllib.parse import urlparse

MAX_DELAY = 5000  # æœ€å¤§å»¶è¿Ÿ ms
MAX_SAVE = 1000   # æœ€å¤§ä¿å­˜èŠ‚ç‚¹æ•°
SUB_FILE = "subs.txt"  # è®¢é˜…é“¾æ¥æ–‡ä»¶å
OUTPUT_FILE = "sub"    # è¾“å‡ºæ–‡ä»¶å
SUPPORTED_PROTOCOLS = ("vmess://", "ss://", "trojan://", "vless://", "hysteria://", "hysteria2://", "tuic://")

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

def is_supported_node(url):
    return url.startswith(SUPPORTED_PROTOCOLS)

def base64_decode_links(data):
    try:
        decoded = base64.b64decode(data).decode("utf-8")
        return [line.strip() for line in decoded.strip().splitlines() if is_supported_node(line)]
    except Exception:
        return [line.strip() for line in data.strip().splitlines() if is_supported_node(line)]

async def fetch_subscription(session, url):
    try:
        async with session.get(url, timeout=5) as resp:  # æŠ“å–è¶…æ—¶5ç§’
            raw = await resp.text()
            return base64_decode_links(raw)
    except Exception as e:
        print(f"[å¤±è´¥] æŠ“å–è®¢é˜…å¤±è´¥ï¼Œè¯·ç¡®è®¤é“¾æ¥æ˜¯å¦æœ‰æ•ˆï¼Œå¹¶å»ºè®®æ³¨é‡Šè¯¥é“¾æ¥ï¼š{url}")
        print(f"     å…·ä½“é”™è¯¯: {e}")
        return []

def extract_host_port(node_url):
    try:
        parsed = urlparse(node_url)
        if parsed.hostname and parsed.port:
            port = int(parsed.port)
            if 0 < port < 65536:
                return f"{parsed.hostname}:{port}"
    except Exception:
        return None
    return None

async def tcp_ping(host, port, timeout=5):  # è¶…æ—¶æ”¹ä¸º5ç§’
    try:
        start = time.perf_counter()
        reader, writer = await asyncio.wait_for(asyncio.open_connection(host, port), timeout)
        end = time.perf_counter()
        writer.close()
        await writer.wait_closed()
        delay = int((end - start) * 1000)
        print(f"æµ‹é€ŸæˆåŠŸ: {host}:{port} å»¶è¿Ÿ {delay}ms")
        return delay
    except Exception as e:
        print(f"æµ‹é€Ÿå¤±è´¥: {host}:{port} é”™è¯¯: {e}")
        return None

async def check_chatgpt_connectivity():
    if not OPENAI_API_KEY:
        print("[é”™è¯¯] ç¯å¢ƒå˜é‡ OPENAI_API_KEY æœªè®¾ç½®ï¼Œæ— æ³•æ£€æµ‹ ChatGPT è¿é€šæ€§")
        return False
    url = "https://api.openai.com/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {OPENAI_API_KEY}",
        "Content-Type": "application/json",
    }
    json_data = {
        "model": "gpt-3.5-turbo",
        "messages": [{"role": "user", "content": "Hello"}],
        "max_tokens": 1,
    }
    try:
        async with aiohttp.ClientSession() as session:
            async with session.post(url, headers=headers, json=json_data, timeout=10) as resp:
                if resp.status == 200:
                    print("ChatGPT è¿é€šæµ‹è¯•æˆåŠŸ")
                    return True
                else:
                    print(f"[é”™è¯¯] ChatGPT è¿é€šæµ‹è¯•å¤±è´¥ï¼ŒçŠ¶æ€ç : {resp.status}")
                    return False
    except Exception as e:
        print(f"[é”™è¯¯] ChatGPT è¿é€šæµ‹è¯•å¼‚å¸¸: {e}")
        return False

async def test_single_node(node):
    try:
        parsed = urlparse(node)
        host, port = parsed.hostname, parsed.port
        if not host or not port:
            print(f"èŠ‚ç‚¹æ ¼å¼é”™è¯¯ï¼Œæ— æ³•è§£æ host æˆ– port: {node}")
            return None
        delay = await tcp_ping(host, port, timeout=5)
        if delay is None or delay > MAX_DELAY:
            return None
        # ChatGPTæ£€æµ‹
        chatgpt_ok = await check_chatgpt_connectivity()
        if not chatgpt_ok:
            print(f"èŠ‚ç‚¹ {node} å»¶è¿Ÿåˆæ ¼ï¼Œä½† ChatGPT è¿é€šæ£€æµ‹æœªé€šè¿‡")
            return None
        return node, delay
    except Exception as e:
        print(f"èŠ‚ç‚¹æµ‹è¯•å¼‚å¸¸: {e}")
        return None

def print_progress(percent, success_count):
    line = f"æµ‹è¯•èŠ‚ç‚¹è¿›åº¦: {percent:6.2f}% | æˆåŠŸ: {success_count}"
    max_len = 50
    padded_line = line + " " * (max_len - len(line))
    print("\r" + padded_line, end="", flush=True)

async def test_all_nodes(nodes):
    total = len(nodes)
    success_count = 0
    done_count = 0
    results = []
    sem = asyncio.Semaphore(32)
    last_print_percent = 0

    async def test_node(node):
        nonlocal success_count, done_count, last_print_percent
        async with sem:
            res = await test_single_node(node)
            if res is not None:
                results.append(res)
                success_count += 1
            done_count += 1
            percent = done_count / total * 100
            if percent - last_print_percent >= 5 or percent == 100:
                print_progress(percent, success_count)
                last_print_percent = percent

    tasks = [test_node(node) for node in nodes]
    await asyncio.gather(*tasks)
    print()  # æ¢è¡Œé¿å…è¿›åº¦å¡ä½ä¸€è¡Œ

    results.sort(key=lambda x: x[1])
    return [node for node, delay in results[:MAX_SAVE]]

async def main():
    print("ğŸ“¥ è¯»å–è®¢é˜…é“¾æ¥...")
    try:
        with open(SUB_FILE, "r", encoding="utf-8") as f:
            urls = [line.strip() for line in f if line.strip() and not line.strip().startswith("#")]
    except FileNotFoundError:
        print(f"[é”™è¯¯] æœªæ‰¾åˆ°æ–‡ä»¶ {SUB_FILE}")
        return

    print("ğŸŒ æŠ“å–è®¢é˜…å†…å®¹ä¸­...")
    async with aiohttp.ClientSession() as session:
        all_nodes = []
        failed_urls = []
        for url in urls:
            nodes = await fetch_subscription(session, url)
            if nodes:
                print(f"[æˆåŠŸ] æŠ“å–è®¢é˜…ï¼š{url}ï¼ŒèŠ‚ç‚¹æ•°: {len(nodes)}")
                all_nodes.extend(nodes)
            else:
                failed_urls.append(url)

    # å¤±è´¥è®¢é˜…è‡ªåŠ¨æ³¨é‡Šå†™å›æ–‡ä»¶
    if failed_urls:
        print(f"âœï¸ æ ‡è®°å¤±è´¥è®¢é˜…é“¾æ¥ä¸ºæ³¨é‡Š...")
        try:
            with open(SUB_FILE, "r", encoding="utf-8") as f:
                lines = f.readlines()
            with open(SUB_FILE, "w", encoding="utf-8") as f:
                for line in lines:
                    if any(url in line for url in failed_urls) and not line.startswith("#"):
                        f.write("# " + line)
                    else:
                        f.write(line)
        except Exception as e:
            print(f"[é”™è¯¯] å¤±è´¥è®¢é˜…æ³¨é‡Šå†™å›å¤±è´¥: {e}")

    print(f"ğŸ“Š æŠ“å–å®Œæˆï¼ŒèŠ‚ç‚¹æ€»æ•°ï¼ˆå«é‡å¤ï¼‰: {len(all_nodes)}")

    # å»é‡é€»è¾‘ä¼˜åŒ–ï¼Œkey = host:port
    unique_nodes_map = {}
    for node in all_nodes:
        key = extract_host_port(node)
        if key and key not in unique_nodes_map:
            unique_nodes_map[key] = node

    unique_nodes = list(unique_nodes_map.values())
    print(f"ğŸ¯ å»é‡åèŠ‚ç‚¹æ•°: {len(unique_nodes)}")

    print(f"ğŸš¦ å¼€å§‹èŠ‚ç‚¹å»¶è¿ŸåŠChatGPTè¿é€šæµ‹è¯•ï¼Œå…± {len(unique_nodes)} ä¸ªèŠ‚ç‚¹")
    tested_nodes = await test_all_nodes(unique_nodes)

    print(f"\nâœ… æµ‹è¯•å®Œæˆ: æˆåŠŸ {len(tested_nodes)} / æ€» {len(unique_nodes)}")

    if not tested_nodes:
        print("[ç»“æœ] æ— å¯ç”¨èŠ‚ç‚¹")
        return

    combined = "\n".join(tested_nodes)
    encoded = base64.b64encode(combined.encode("utf-8")).decode("utf-8")

    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        f.write(encoded)

    print(f"ğŸ“¦ æœ‰æ•ˆèŠ‚ç‚¹å·²ä¿å­˜: {OUTPUT_FILE}ï¼ˆå…± {len(tested_nodes)} ä¸ªï¼‰")

if __name__ == "__main__":
    asyncio.run(main())
