import asyncio
import aiohttp
import base64
import time
from urllib.parse import urlparse
from asyncio import Semaphore
import sys
from tqdm import tqdm

MAX_DELAY = 5000
MAX_SAVE = 1000
SUB_FILE = "subs.txt"
OUTPUT_FILE = "sub"  # è¾“å‡ºæ–‡ä»¶åæ”¹ä¸º subï¼ˆæ— æ‰©å±•åï¼‰
SUPPORTED_PROTOCOLS = ("vmess://", "ss://", "trojan://", "vless://", "hysteria://", "hysteria2://", "tuic://")

def is_supported_node(url):
    return url.startswith(SUPPORTED_PROTOCOLS)

def base64_decode_links(data):
    try:
        decoded = base64.b64decode(data).decode("utf-8")
        return [line.strip() for line in decoded.strip().splitlines() if is_supported_node(line)]
    except Exception:
        # è§£ç å¤±è´¥å½“ä½œçº¯æ–‡æœ¬é€è¡Œå¤„ç†
        return [line.strip() for line in data.strip().splitlines() if is_supported_node(line)]

def extract_host_port(node_url):
    try:
        parsed = urlparse(node_url)
        host = parsed.hostname
        port = parsed.port

        if port is None:
            return None

        if not (1 <= port <= 65535):
            print(f"[è­¦å‘Š] ç«¯å£è¶…å‡ºèŒƒå›´æˆ–éæ³•: {port}ï¼ŒèŠ‚ç‚¹: {node_url}")
            return None

        if host is None:
            return None

        return f"{host}:{port}"

    except Exception as e:
        print(f"[è­¦å‘Š] èŠ‚ç‚¹åœ°å€è§£æå¼‚å¸¸ {node_url}: {e}")
        return None

async def fetch_subscription(session, url):
    try:
        async with session.get(url, timeout=10) as resp:
            raw = await resp.text()
            return base64_decode_links(raw)
    except Exception:
        return []

async def tcp_ping(host, port, timeout=5):
    loop = asyncio.get_event_loop()
    try:
        await asyncio.wait_for(loop.getaddrinfo(host, port), timeout)
        start = time.perf_counter()
        reader, writer = await asyncio.wait_for(asyncio.open_connection(host, port), timeout)
        end = time.perf_counter()
        writer.close()
        await writer.wait_closed()
        return int((end - start) * 1000)
    except Exception:
        return None

async def test_single_node(node):
    try:
        parsed = urlparse(node)
        host, port = parsed.hostname, parsed.port
        if not host or not port:
            return None
        delay = await tcp_ping(host, port, timeout=5)
        if delay is None or delay > MAX_DELAY:
            return None
        return delay
    except Exception:
        return None

async def test_all_nodes(nodes):
    sem = Semaphore(32)
    results = []

    async def test_node(node):
        async with sem:
            delay = await test_single_node(node)
            if delay is not None and delay <= MAX_DELAY:
                return (node, delay)
            return None

    tasks = [asyncio.create_task(test_node(node)) for node in nodes]

    for coro in tqdm(asyncio.as_completed(tasks), total=len(nodes), desc="æµ‹è¯•èŠ‚ç‚¹è¿›åº¦"):
        try:
            res = await coro
            if res:
                results.append(res)
        except Exception as e:
            print(f"[å¼‚å¸¸] å•èŠ‚ç‚¹æµ‹è¯•å‡ºé”™: {e}")

    results.sort(key=lambda x: x[1])
    top_nodes = [node for node, delay in results[:MAX_SAVE]]

    return top_nodes

async def main():
    print("ğŸ“¥ è¯»å–è®¢é˜…é“¾æ¥...")
    try:
        with open(SUB_FILE, "r", encoding="utf-8") as f:
            urls = [line.strip() for line in f if line.strip()]
    except FileNotFoundError:
        print(f"[é”™è¯¯] æœªæ‰¾åˆ°æ–‡ä»¶ {SUB_FILE}")
        return

    print("ğŸŒ æŠ“å–è®¢é˜…å†…å®¹ä¸­...")
    async with aiohttp.ClientSession() as session:
        all_nodes = []
        for url in urls:
            nodes = await fetch_subscription(session, url)
            if nodes:
                print(f"[æˆåŠŸ] æŠ“å–è®¢é˜…ï¼š{url}ï¼ŒèŠ‚ç‚¹æ•°: {len(nodes)}")
                all_nodes.extend(nodes)
            else:
                print(f"[å¤±è´¥] æŠ“å–è®¢é˜…ï¼š{url}")

    print(f"ğŸ“Š æŠ“å–å®Œæˆï¼ŒèŠ‚ç‚¹æ€»æ•°ï¼ˆå«é‡å¤ï¼‰: {len(all_nodes)}")

    unique_nodes_map = {}
    for node in all_nodes:
        key = extract_host_port(node)
        if key and key not in unique_nodes_map:
            unique_nodes_map[key] = node

    unique_nodes = list(unique_nodes_map.values())
    print(f"ğŸ¯ å»é‡åèŠ‚ç‚¹æ•°: {len(unique_nodes)}")

    print(f"ğŸš¦ å¼€å§‹èŠ‚ç‚¹å»¶è¿Ÿæµ‹è¯•ï¼Œå…± {len(unique_nodes)} ä¸ªèŠ‚ç‚¹")
    tested_nodes = await test_all_nodes(unique_nodes)

    print(f"\nâœ… æµ‹è¯•å®Œæˆ: æˆåŠŸ {len(tested_nodes)} / æ€» {len(unique_nodes)}")

    if not tested_nodes:
        print("[ç»“æœ] æ— å¯ç”¨èŠ‚ç‚¹")
        return

    combined = "\n".join(tested_nodes)
    encoded = base64.b64encode(combined.encode("utf-8")).decode("utf-8")

    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        f.write(encoded)

    print(f"ğŸ“¦ æœ‰æ•ˆèŠ‚ç‚¹å·²ä¿å­˜: {OUTPUT_FILE}ï¼ˆå…± {len(tested_nodes)} ä¸ªï¼‰")

if __name__ == "__main__":
    asyncio.run(main())
